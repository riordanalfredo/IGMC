{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598319544576",
   "display_name": "Python 3.6.10 64-bit ('igcmf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import h5py\n",
    "import hdf5storage\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import one_hot\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_df(file_path, col_removed, col_features, separator=r'|', encoding='latin-1', ):\n",
    "    col = np.concatenate((col_removed,col_features)) \n",
    "\n",
    "    # extract data from csv\n",
    "    df = pd.read_csv(file_path, sep=separator, names=col, header=None, engine='python', encoding=encoding)\n",
    "\n",
    "    # df = user_item_df.join(item_genre_df.set_index('item_id'), on='item_id')  # combine 2 dfs\n",
    "    df = df.drop(col_removed, axis=1) # delete unwanted columns\n",
    "    col_length = len(df.columns)\n",
    "\n",
    "    return df, col_length\n",
    "\n",
    "def store_into_matlab(data, dataset, mat_file_name, main_location='../raw_data/',):\n",
    "    ds = sorted(data.items())\n",
    "    base_data, training_data, testing_data = [d[1] for d in ds]\n",
    "    matdict = {'M': base_data,'Otraining': training_data.numpy() ,'Otest': testing_data.numpy()}\n",
    "    \n",
    "    path_store =  main_location + dataset + '/'+ mat_file_name\n",
    "    hdf5storage.write(matdict, '.', path_store, matlab_compatible=True)\n",
    "    print('Sucessfully created '+ mat_file_name+ '.mat file at' + path_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(clean_df, col_length):\n",
    "\n",
    "    torch_base = torch.tensor(clean_df, dtype=torch.long)\n",
    "    base_data = clean_df\n",
    "    idx_base = torch.nonzero(torch_base)\n",
    "    \n",
    "    # Create training matrix\n",
    "    # Select about 20% randomly from the idx array \n",
    "    n = int(0.2*len(idx_base))\n",
    " \n",
    "    print('number of test:', n) \n",
    "    idx = np.random.choice(idx_base.shape[0], n, replace=False)\n",
    "\n",
    "    # Use the dropout index as training set\n",
    "    idx_training = [e.numpy() for i,e in enumerate(idx_base) if i not in idx] \n",
    "    print(\"training percentage: \", len(idx_training)/len(idx_base))\n",
    "    row_length = len(base_data)\n",
    "    training_data = torch.zeros(row_length,col_length)\n",
    "    for i in idx_training:\n",
    "        # print(training_data[i[0],i[1]])\n",
    "        training_data[i[0],i[1]] = torch.tensor(1, dtype=torch.int64)\n",
    "\n",
    "    idx_testing = [e.numpy() for i,e in enumerate(idx_base) if i in idx] \n",
    "    testing_data = torch.zeros(row_length, col_length)\n",
    "    for i in idx_testing:\n",
    "        testing_data[i[0],i[1]] = torch.tensor(1, dtype=torch.int64)\n",
    "    \n",
    "    print('base data shape:',base_data.shape)\n",
    "    print('train data shape:',training_data.shape)\n",
    "    print('test data shape:',testing_data.shape)\n",
    "\n",
    "    data = {'base_data': base_data, 'training_data': training_data, 'testing_data': testing_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_feature_df(raw_df, col_length):\n",
    "   \n",
    "    users_df = raw_df\n",
    "    num_users = users_df.shape[0]\n",
    "    users = set(users_df['user id'].values.tolist())\n",
    "    occupation = set(users_df['occupation'].values.tolist())\n",
    "\n",
    "    age = users_df['age'].values\n",
    "    age_max = age.max()\n",
    "\n",
    "    gender_dict = {'M': 0., 'F': 1.}\n",
    "    u_dict={f: i for i, f in enumerate(users, start=0)}\n",
    "    occupation_dict = {f: i for i, f in enumerate(occupation, start=2)}\n",
    "\n",
    "    num_feats = 2 + len(occupation_dict)\n",
    "\n",
    "    u_features = np.zeros((num_users, num_feats), dtype=np.float32)\n",
    "    for _, row in users_df.iterrows():\n",
    "        u_id = row['user id']\n",
    "        if u_id in u_dict.keys():\n",
    "            # age\n",
    "            u_features[u_dict[u_id], 0] = row['age'] / np.float(age_max)\n",
    "            # gender\n",
    "            u_features[u_dict[u_id], 1] = gender_dict[row['gender']]\n",
    "            # occupation\n",
    "            u_features[u_dict[u_id],\n",
    "                        occupation_dict[row['occupation']]] = 1.\n",
    "    return u_features, num_feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of test: 578\ntraining percentage:  0.8002073971655721\nbase data shape: (1682, 19)\ntrain data shape: torch.Size([1682, 19])\ntest data shape: torch.Size([1682, 19])\nSucessfully created item_features.mat file at../raw_data/ml_100k/item_features\n"
    }
   ],
   "source": [
    "# create item_features dataset in matlab\n",
    "item_path = \"../raw_data/ml_100k/u.item\" # TODO: attach it somewhere\n",
    "col_removed = ['item_id','title','date','url']\n",
    "col_features = ['unknown', 'action', 'adventure', 'animation' , 'children' , 'comedy' , 'crime' , 'documentary' , 'drama' , 'fantasy' ,'noir' , 'horror' , 'musical' , 'mystery' , 'romance' , 'scifi' ,'thriller' , 'war' , 'western']\n",
    "df, col_length = cleaning_df(item_path, col_removed, col_features)\n",
    "clean_df = df.to_numpy()\n",
    "\n",
    "data = split_data(clean_df, col_length)\n",
    "store_into_matlab(data, 'ml_100k', 'item_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of test: 243\ntraining percentage:  0.8003286770747741\nbase data shape: (943, 23)\ntrain data shape: torch.Size([943, 23])\ntest data shape: torch.Size([943, 23])\nSucessfully created user_features.mat file at../raw_data/ml_100k/user_features\n"
    }
   ],
   "source": [
    "# create user_features dataset in matlab\n",
    "item_path = \"../raw_data/ml_100k/u.user\" # TODO: attach it somewhere\n",
    "col_removed = []\n",
    "col_features = ['user id', 'age', 'gender', 'occupation', 'zip code']\n",
    "\n",
    "df, col_length = cleaning_df(item_path, col_removed, col_features)\n",
    "clean_df, num_feats = generate_user_feature_df(df, col_length)\n",
    "\n",
    "data = split_data(clean_df, num_feats)\n",
    "store_into_matlab(data, 'ml_100k', 'user_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNUSED BLOCKS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   user_id  item_id  relation\n0        1        1         5\n1        1        2         3\n2        1        3         4\n3        1        4         3\n4        1        5         3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>relation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# NOT USED!\n",
    "def create_df(csv_path):\n",
    "        col_names = ['user_id', 'item_id', 'relation', 'ts']\n",
    "        df = pd.read_csv(csv_path, sep='\\t', names=col_names)\n",
    "        df = df.drop('ts', axis=1)\n",
    "        df_copy = df.copy()\n",
    "        df['user_id'] = df['user_id'] - 1\n",
    "        df['item_id'] = df['item_id'] - 1\n",
    "        df['relation'] = df['relation'] - 1\n",
    "\n",
    "        nums = {'user': df.max()['user_id'] + 1,\n",
    "                'item': df.max()['item_id'] + 1,\n",
    "                'node': df.max()['user_id'] + df.max()['item_id'] + 2,\n",
    "                'edge': len(df)}\n",
    "        return df_copy, nums\n",
    "\n",
    "csv_path = \"../raw_data/ml_100k/u1.base\" # TODO: attach it somewhere \n",
    "user_item_df, nums = create_df(csv_path)\n",
    "user_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1, 0, 0], [0, 1, 0], [0, 1, 1]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 0, 0],\n        [0, 0, 0],\n        [0, 1, 0]])"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "\n",
    "x = [[1,0,0],[0,1,0],[0,1,1]]\n",
    "a = torch.tensor(x, dtype=torch.int64)\n",
    "indices = torch.tensor([[1,1],[2,2]])\n",
    "\n",
    "print(x)\n",
    "a\n",
    "# a[torch.arange(a.size(0)).unsqueeze(1), indices] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 0., 0., 0., 0.],\n        [0., 1., 1., 0., 0., 0.],\n        [0., 1., 0., 0., 1., 0.]])"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "index = torch.tensor([[ 0,  1],\n",
    "                [ 1,  2],\n",
    "                [ 4,  1]], dtype=torch.long)\n",
    "a = torch.Tensor([[ 0,  0,  0,  0,  0,  0],[ 0,  0,  0,  0,  0,  0],[ 0,  0,  0,  0,  0,  0]])\n",
    "\n",
    "for i, ind in enumerate(index):\n",
    "    a[i].index_fill_(0, ind, 1)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}